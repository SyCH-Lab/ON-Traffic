{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import importlib\n",
    "import tools_torch\n",
    "importlib.reload(tools_torch)\n",
    "from tools_torch import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../datasets/godunov_combined_tpast2_tpred8_receding.npz\")\n",
    "\n",
    "# Extract the data\n",
    "branch_coords = torch.tensor(data['branch_coords'])\n",
    "branch_values = torch.tensor(data['branch_values'])\n",
    "output_sensor_coords = torch.tensor(data['output_sensor_coords'])\n",
    "output_sensor_values = torch.tensor(data['output_sensor_values'])\n",
    "rho = torch.tensor(data['rho'])\n",
    "x = torch.tensor(data['x'])\n",
    "t = torch.tensor(data['t'])\n",
    "Nx = data['Nx'].item()\n",
    "Nt = data['Nt'].item()\n",
    "Xmax = data['Xmax'].item()\n",
    "Tmax = data['Tmax'].item()\n",
    "N = data['N'].item()\n",
    "T_PAST = data['t_past'].item()\n",
    "T_PRED = data['t_pred'].item()\n",
    "t_starts = torch.tensor(data['t_starts'])\n",
    "\n",
    "\n",
    "print(f\"Nx = {Nx}, Nt = {Nt}, Xmax = {Xmax}, Tmax = {Tmax}, N = {N}\")\n",
    "print(f\"branch_coords.shape = {branch_coords.shape}, branch_values.shape = {branch_values.shape}, output_sensor_coords.shape = {output_sensor_coords.shape}, \")\n",
    "print(f\"output_sensor_values.shape = {output_sensor_values.shape}, x.shape = {x.shape}, t.shape = {t.shape}\")\n",
    "print(f\"t_starts = {t_starts.shape}, rho.shape = {rho.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the validation percentage\n",
    "validation_percentage = 0.2\n",
    "\n",
    "branch_coords_train, branch_coords_val, branch_values_train, branch_values_val, \\\n",
    "output_sensor_coords_train, output_sensor_coords_val, output_sensor_values_train, output_sensor_values_val, rho_train, rho_val, \\\n",
    "t_starts_train, t_starts_val = train_test_split(\n",
    "    branch_coords, branch_values, output_sensor_coords, output_sensor_values, rho, t_starts,\n",
    "    test_size=validation_percentage, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "batch_size = 32 \n",
    "train_dataset = DeepONetDatasetTrain(branch_coords_train[:,:,:], branch_values_train[:,:,0:1], output_sensor_coords_train, output_sensor_values_train, device=device) # branch_coord, branch_values, trunk_coords, targets, UU\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dataset = DeepONetDatasetTrain(branch_coords_val[:,:,:], branch_values_val[:,:,0:1], output_sensor_coords_val, output_sensor_values_val, device=device)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "xs, us, ys, ss = next(iter(train_loader))\n",
    "print(f\"train shapes\\t xs: {xs.shape}, us: {us.shape}, ys: {ys.shape}, ss: {ss.shape}, device: {xs.device}\")\n",
    "xs, us, ys, ss = next(iter(val_loader))\n",
    "print(f\"val shapes\\t xs: {xs.shape}, us: {us.shape}, ys: {ys.shape}, ss: {ss.shape}, device: {xs.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=3\n",
    "plt.scatter(ys[idx,:,1].cpu().numpy(), ys[idx,:,0].cpu().numpy(), c=ss[idx,:].cpu().numpy(), label='output sensors',  cmap='jet', vmin=0, vmax=1)\n",
    "plt.figure()\n",
    "plt.scatter(xs[idx,:,1].cpu().numpy(), xs[idx,:,0].cpu().numpy(), c=us[idx,:,0].cpu().numpy(), label='branch sensors', cmap='jet', vmin=0, vmax=1)\n",
    "plt.ylim(0), plt.xlim(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "from vidon_model import VIDON, FDLearner\n",
    "p = 400\n",
    "model = VIDON(p=p, num_heads=4, d_branch_input=2, d_v=1, use_linear_decoder=False, UQ=True).to(device)\n",
    "model.to(device)\n",
    "FD = FDLearner(d_FD=50)\n",
    "FD.to(device)\n",
    "\n",
    "# Define the loss function \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 100\n",
    "# Define the optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)#, weight_decay=1e-10) #\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.2,\n",
    "    patience=50,\n",
    "    min_lr=1e-7,\n",
    "    cooldown=5,\n",
    "    verbose=True\n",
    ")\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "# print number of parameters\n",
    "print(f\"Number of parameters in coord encoder: {sum(p.numel() for p in model.branch.coord_encoder.parameters())}\")\n",
    "print(f\"Number of parameters in value encoder: {sum(p.numel() for p in model.branch.value_encoder.parameters())}\")\n",
    "print(f\"Number of parameters in combiner: {sum(p.numel() for p in model.branch.combiner.parameters())}\")\n",
    "print(f\"Number of parameters in nonlinear decoder: {sum(p.numel() for p in model.nonlinear_decoder.parameters())}\")\n",
    "print(f\"Number of parameters in trunk: {sum(p.numel() for p in model.trunk.parameters())}\")\n",
    "print(f\"Number of parameters in FD:  \\t{sum(p.numel() for p in FD.parameters())}\")\n",
    "print(f\"Number of parameters in model: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_norms = []\n",
    "loss_list = []\n",
    "loss_ic_list = []\n",
    "val_loss_list = []\n",
    "val_loss_mse_list = []\n",
    "lrs = []\n",
    "val_loss = 0\n",
    "lowest_val_loss = 1e6\n",
    "\n",
    "\n",
    "# Training loop \n",
    "pbar = tqdm(range(num_epochs))\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    losses = []\n",
    "    losses_ic = []\n",
    "    \n",
    "    for branch_coord, branch_values, trunk_coords, targets in train_loader:\n",
    "\n",
    "        # bring to gpu\n",
    "        branch_coord = branch_coord.to(device)\n",
    "        branch_values = branch_values.to(device)\n",
    "        trunk_coords = trunk_coords.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # select random parts\n",
    "        sampled_trunk_coords, sampled_targets = sample_trunk_inputs(trunk_coords, targets)\n",
    "        sampled_branch_coord, sampled_branch_values = sample_branch_inputs_keep_boundary(branch_coord, branch_values)\n",
    "    \n",
    "        # forward pass for rho and v with automatic mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs_rho, outputs_rho_sigm = model(sampled_branch_coord[:,:,:2], sampled_branch_values, sampled_trunk_coords)\n",
    "            outputs_rho_sigm = torch.exp(outputs_rho_sigm) + 1e-8\n",
    "\n",
    "            # Compute the loss\n",
    "            loss_first_term = (outputs_rho - sampled_targets) ** 2 / (2 * (outputs_rho_sigm) ** 2)\n",
    "            loss_second_term = 0.5 * torch.log(2 * torch.pi * (outputs_rho_sigm) ** 2)\n",
    "            loss_UQ = torch.mean(loss_first_term + loss_second_term)\n",
    "            mse_loss = criterion(outputs_rho, sampled_targets)\n",
    "            loss = loss_UQ/300 + mse_loss\n",
    "\n",
    "            losses.append(mse_loss.item())\n",
    "        \n",
    "        # Backward pass with scaled gradients\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3.0)  # Clip gradient norm\n",
    "        \n",
    "        # Update weights\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    \n",
    "    loss_list.append(np.mean(losses))\n",
    "\n",
    "    # validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        val_losses_mse = []\n",
    "        T_START = 0 \n",
    "\n",
    "        # Timing evaluation\n",
    "        for branch_coord, branch_values, trunk_coords, targets in val_loader:\n",
    "            branch_coord = branch_coord.to(device)\n",
    "            branch_values = branch_values.to(device)\n",
    "            trunk_coords = trunk_coords.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            \n",
    "            with autocast():\n",
    "                outputs_rho, outputs_rho_sigm = model(branch_coord[:,:,:2], branch_values, trunk_coords)\n",
    "                outputs_rho_sigm = torch.exp(outputs_rho_sigm) + 1e-8\n",
    "\n",
    "                # # Compute the loss\n",
    "                loss_first_term = (outputs_rho - targets) ** 2 / (2 * outputs_rho_sigm)\n",
    "                loss_second_term = 0.5 * torch.log(2 * torch.pi * outputs_rho_sigm)\n",
    "                val_loss = torch.mean(loss_first_term + loss_second_term).item()\n",
    "                val_loss_mse = criterion(outputs_rho, targets).item()\n",
    "                \n",
    "                val_losses_mse.append(val_loss_mse)\n",
    "    \n",
    "    val_loss_mse_list.append(np.mean(val_losses_mse))\n",
    "\n",
    "pbar.set_postfix({'Loss': loss.item(), 'Val Loss': val_loss, 'Val Loss MSE': np.mean(val_losses_mse)})\n",
    "\n",
    "\n",
    "if np.mean(val_losses_mse) < lowest_val_loss:\n",
    "    lowest_val_loss = np.mean(val_losses_mse)\n",
    "    print(f\"Saving model with lowest validation loss: {lowest_val_loss}\")\n",
    "    torch.save(model.state_dict(), f'trained_model.pth')\n",
    "\n",
    "\n",
    "scheduler.step(np.mean(val_losses_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(loss_list, label='training loss')\n",
    "plt.semilogy(val_loss_mse_list, label='validation loss') \n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graduation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
