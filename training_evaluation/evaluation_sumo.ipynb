{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "torch.cuda.empty_cache()\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import importlib\n",
    "import tools_torch\n",
    "importlib.reload(tools_torch)\n",
    "from tools_torch import *\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../datasets/sumo/receding_sumo_idm_dataset_tpast2_tpred8.npz')\n",
    "\n",
    "\n",
    "# Extract the data\n",
    "branch_coords = torch.tensor(data['branch_coords'])\n",
    "branch_values = torch.tensor(data['branch_values'])\n",
    "output_sensor_coords = torch.tensor(data['output_sensor_coords'])\n",
    "output_sensor_values = torch.tensor(data['output_sensor_values'])\n",
    "rho = torch.tensor(data['rho'])\n",
    "Nx = data['Nx'].item()\n",
    "Nt = data['Nt'].item()\n",
    "Xmax = data['Xmax'].item()\n",
    "Tmax = data['Tmax'].item()\n",
    "N = data['N'].item()\n",
    "t_starts = torch.tensor(data['t_starts'])\n",
    "t_pred = torch.tensor(data['t_pred'])\n",
    "t_past = torch.tensor(data['t_past'])\n",
    "\n",
    "\n",
    "print(f\"Nx = {Nx}, Nt = {Nt}, Xmax = {Xmax}, Tmax = {Tmax}, N = {N}\")\n",
    "print(f\"branch_coords.shape = {branch_coords.shape}, branch_values.shape = {branch_values.shape}, output_sensor_coords.shape = {output_sensor_coords.shape}, \")\n",
    "print(f\"t_starts = {t_starts.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the validation percentage\n",
    "validation_percentage = 0.2  # validation\n",
    "\n",
    "branch_coords_train, branch_coords_val, branch_values_train, branch_values_val, \\\n",
    "output_sensor_coords_train, output_sensor_coords_val, output_sensor_values_train, output_sensor_values_val, rho_train, rho_val, \\\n",
    "t_starts_train, t_starts_val = train_test_split(\n",
    "    branch_coords, branch_values, output_sensor_coords, output_sensor_values, rho, t_starts,\n",
    "    test_size=validation_percentage, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "batch_size = 32\n",
    "train_dataset = DeepONetDatasetTrain(branch_coords_train[:,:,:], branch_values_train[:,:,0:1], output_sensor_coords_train, output_sensor_values_train, device=device) # branch_coord, branch_values, trunk_coords, targets, UU\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_dataset = DeepONetDatasetTrain(branch_coords_val[:,:,:], branch_values_val[:,:,0:1], output_sensor_coords_val, output_sensor_values_val, device=device)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "xs, us, ys, ss = next(iter(train_loader))\n",
    "print(f\"train shapes\\t xs: {xs.shape}, us: {us.shape}, ys: {ys.shape}, ss: {ss.shape}, device: {xs.device}\")\n",
    "xs, us, ys, ss = next(iter(val_loader))\n",
    "print(f\"val shapes\\t xs: {xs.shape}, us: {us.shape}, ys: {ys.shape}, ss: {ss.shape}, device: {xs.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "from vidon_model import VIDON, FDLearner\n",
    "p = 400\n",
    "model = VIDON(p=p, num_heads=4, d_branch_input=3, d_v=2, use_linear_decoder=False, UQ=True).to(device)\n",
    "model.to(device)\n",
    "FD = FDLearner(d_FD=50)\n",
    "FD.to(device)\n",
    "\n",
    "# Define the loss function \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_sumo_19_11_past4_pred6_2_phys_UQ.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_test = batch_size\n",
    "train_dataset_test = DeepONetDataset(branch_coords_train[:,:,:], branch_values_train[:,:,0:], output_sensor_coords_train, output_sensor_values_train, rho_train, device=device, t_start=t_starts_train) # branch_coord, branch_values, trunk_coords, targets, UU\n",
    "train_loader_test = DataLoader(train_dataset_test, batch_size=batch_size_test, shuffle=True)\n",
    "val_dataset_test = DeepONetDataset(branch_coords_val[:,:,:], branch_values_val[:,:,0:], output_sensor_coords_val, output_sensor_values_val, rho_val, device=device, t_start=t_starts_val)\n",
    "val_loader_test = DataLoader(val_dataset_test, batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate model on validation set\n",
    "model.eval()\n",
    "FD.eval()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "losses = []  # Initialize for tracking loss\n",
    "mae_errors = []  # Initialize for tracking MAE\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (branch_coords, branch_values, trunk_coords, trunk_values, rhos, tstarts) in tqdm(enumerate(val_loader_test)):\n",
    "        branch_coords = branch_coords.to(device)\n",
    "        branch_values = branch_values.to(device)\n",
    "        trunk_coords = trunk_coords.to(device)\n",
    "        trunk_values = trunk_values.to(device)\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            rho_pred, sigma = model(branch_coords[:,:,:], branch_values, trunk_coords)\n",
    "            loss = criterion(rho_pred, trunk_values)\n",
    "            mae = F.l1_loss(rho_pred, trunk_values, reduction='mean')  # Calculate MAE\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        mae_errors.append(mae.item())\n",
    "\n",
    "# Calculate mean of the losses and MAE errors\n",
    "validation_loss = np.mean(losses)\n",
    "mean_absolute_error = np.mean(mae_errors)\n",
    "\n",
    "print(f\"Validation loss: {validation_loss}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
