{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from godunov_vis_tools import * \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = np.load('../datasets/godunov_100_combined.npz', allow_pickle=True)\n",
    "\n",
    "# Extract the data\n",
    "branch_coords = data['branch_coords']\n",
    "branch_values = data['branch_values']\n",
    "output_sensor_coords = data['output_sensor_coords']\n",
    "output_sensor_values = data['output_sensor_values']\n",
    "rho = data['rho']\n",
    "# v = data['v']\n",
    "x = data['x']\n",
    "tt = data['t']\n",
    "Nx = data['Nx']\n",
    "Nt = data['Nt']\n",
    "Xmax = data['Xmax']\n",
    "Tmax = data['Tmax']\n",
    "P = data['P']\n",
    "N = data['N']\n",
    "# keys = data['keys']\n",
    "\n",
    "\n",
    "print(f\"branch_coords.shape = {branch_coords.shape}, branch_values.shape = {branch_values.shape}, output_sensor_coords.shape = {output_sensor_coords.shape}, \")\n",
    "print(f\"output_sensor_values.shape = {output_sensor_values.shape}, rho.shape = {rho.shape}, x.shape = {x.shape}, t.shape = {tt.shape}\")\n",
    "print(f\"Nx = {Nx}, Nt = {Nt}, Xmax = {Xmax}, Tmax = {Tmax}, P = {P}, N = {N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_stats_npz(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "n_probes = 8 \n",
    "max_id = 0\n",
    "min_id = 1e6\n",
    "\n",
    "T_PRED = 8\n",
    "T_PAST = 2\n",
    "\n",
    "branch_coords_filtered_list, branch_values_filtered_list = [], []\n",
    "output_sensor_coords_filtered_list, output_sensor_values_filtered_list = [], []\n",
    "shapes_branch, shapes_trunk = [], []\n",
    "shapes_branch_neg_1 = []\n",
    "shapes_branch_other = []\n",
    "t_starts = []\n",
    "\n",
    "tt_sub = tt[:,::5]\n",
    "tt_starts = tt_sub[tt_sub <= Tmax - T_PRED - T_PAST]\n",
    "\n",
    "seed=0\n",
    "# set the seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# for every scenario\n",
    "for idx in tqdm(range(len(branch_coords))):\n",
    "\n",
    "    # randomly sample a shift between 0 and T_max - T_PRED - T_PAST\n",
    "    t_start = np.random.choice(tt_starts)\n",
    "    t = t_start + T_PAST\n",
    "    t_starts.append(t_start)\n",
    "\n",
    "\n",
    "    # Filter out coordinates where ID is -2\n",
    "    coords_probes_boundary = branch_coords[idx][branch_coords[idx, :, 2] != -2]\n",
    "\n",
    "    # Further filter based on t_max for sampling purposes\n",
    "    coords_in_horizon = coords_probes_boundary[(coords_probes_boundary[:, 1] <= t + T_PRED) & (coords_probes_boundary[:, 1] >= t - T_PAST)]\n",
    "\n",
    "    # # Get all unique IDs except -1 and -2\n",
    "    unique_ids = np.unique(coords_in_horizon[:, 2])\n",
    "    unique_ids = unique_ids[(unique_ids != -1) & (unique_ids != -2)]\n",
    "\n",
    "    # Sample IDs with even spacing\n",
    "    sampled_ids = unique_ids[::max(1, len(unique_ids) // n_probes)]  # Evenly spaced selection of IDs\n",
    "\n",
    "    # Create a mask for branch_coords to keep points with the sampled IDs and -1\n",
    "    mask_sampled_ids = np.isin(branch_coords[idx][:, 2], sampled_ids) & (branch_coords[idx][:, 1] <= t) & (branch_coords[idx][:, 1] >= t - T_PAST)\n",
    "    \n",
    "    # Mask for ID == -1 entries\n",
    "    mask_boundary = branch_coords[idx][:, 2] == -1\n",
    "    \n",
    "    # # Remove ID == -1 entries if x location is below 5 or above t_max_boundary\n",
    "    mask_id_neg1_x_above_5 = mask_boundary & (branch_coords[idx][:, 0] >= 4) & (branch_coords[idx][:, 1] <= t + T_PRED) & (branch_coords[idx][:, 1] >= t - T_PAST)\n",
    "    \n",
    "    # Get indices of ID == -1 and evenly sample half the points\n",
    "    neg1_indices = np.where(mask_id_neg1_x_above_5)[0]\n",
    "    # half_neg1_indices = np.random.choice(neg1_indices, size=len(neg1_indices) // 2, replace=False) if len(neg1_indices) > 0 else []\n",
    "    half_neg1_indices = np.random.choice(neg1_indices, size=len(neg1_indices), replace=False) if len(neg1_indices) > 0 else []\n",
    "\n",
    "    # Create a mask for the sampled half of ID == -1\n",
    "    mask_half_neg1 = np.zeros(mask_id_neg1_x_above_5.shape, dtype=bool)\n",
    "    mask_half_neg1[half_neg1_indices] = True\n",
    "    \n",
    "    # Combine the two masks to filter both branch_coords and branch_values\n",
    "    final_mask = mask_sampled_ids | mask_half_neg1\n",
    "\n",
    "    # Apply the final mask to both branch_coords and branch_values\n",
    "    filtered_coords = branch_coords[idx][final_mask]\n",
    "    filtered_values = branch_values[idx][final_mask]\n",
    "\n",
    "    # shift to t = 0\n",
    "    filtered_coords[:, 1] -= t_start\n",
    "\n",
    "    # # Append the filtered coordinates and values to the list\n",
    "    branch_coords_filtered_list.append(filtered_coords)\n",
    "    branch_values_filtered_list.append(filtered_values)\n",
    "\n",
    "    # keep trunk_coords where t is in horizon\n",
    "    output_sensor_coords_filtered = output_sensor_coords[idx][(output_sensor_coords[idx][:, 1] <= t + T_PRED) & (output_sensor_coords[idx][:, 1] >= t - T_PAST)]\n",
    "    output_sensor_values_filtered = output_sensor_values[idx][(output_sensor_coords[idx][:, 1] <= t + T_PRED) & (output_sensor_coords[idx][:, 1] >= t - T_PAST)]\n",
    "\n",
    "    # shift to t = 0\n",
    "    output_sensor_coords_filtered[:, 1] -= t_start\n",
    "\n",
    "    # Append the filtered coordinates and values to the list\n",
    "    output_sensor_coords_filtered_list.append(output_sensor_coords_filtered)\n",
    "    output_sensor_values_filtered_list.append(output_sensor_values_filtered)\n",
    "\n",
    "    shapes_branch.append(filtered_coords.shape[0])\n",
    "    shapes_trunk.append(output_sensor_coords_filtered.shape[0])\n",
    "\n",
    "    # Count the number of id == -1 and id > 0 in the horizon\n",
    "    count_neg_1 = np.sum(filtered_coords[:, 2] == -1)\n",
    "    count_other = np.sum(filtered_coords[:, 2] > 0)\n",
    "\n",
    "    # Append the counts to respective lists\n",
    "    shapes_branch_neg_1.append(count_neg_1)\n",
    "    shapes_branch_other.append(count_other)\n",
    "\n",
    "    # Get the max and min number of IDs\n",
    "    max_id = max(max_id, filtered_coords.shape[0])\n",
    "    min_id = min(min_id, filtered_coords.shape[0])\n",
    "\n",
    "print(f\"max_id = {max_id}, min_id = {min_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "ax[0].plot(sorted(shapes_branch_neg_1)), ax[1].plot(sorted(shapes_branch_other)), ax[2].plot(np.array(sorted(shapes_branch_other)) + np.array(sorted(shapes_branch_neg_1))), ax[3].plot(sorted(shapes_trunk));\n",
    "ax[0].set_title(\"# ID == -1\"), ax[1].set_title(\"# ID > 0\"), ax[2].set_title(\"# ID > 0 + # ID == -1\"), ax[3].set_title(\"# Trunk sensors\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pad_to_shape_branch(coords, values, target_shape_boundary, target_shape_probe):\n",
    "#     # Separate boundary and probe data based on ID in coords\n",
    "#     boundary_data_coords = coords[coords[:, 2] == -1]\n",
    "#     probe_data_coords = coords[coords[:, 2] != -1]\n",
    "    \n",
    "#     boundary_data_values = values[coords[:, 2] == -1]\n",
    "#     probe_data_values = values[coords[:, 2] != -1]\n",
    "    \n",
    "#     # Truncate or pad boundary data to target_shape_boundary\n",
    "#     filtered_boundary_coords = boundary_data_coords[:target_shape_boundary]\n",
    "#     filtered_boundary_values = boundary_data_values[:target_shape_boundary]\n",
    "    \n",
    "#     # Truncate or pad probe data to target_shape_probe\n",
    "#     if probe_data_coords.shape[0] < target_shape_probe:\n",
    "#         # Pad if probe data is smaller than target_shape_probe\n",
    "#         pad_size = target_shape_probe - probe_data_coords.shape[0]\n",
    "        \n",
    "#         # Generate random values from existing probe data\n",
    "#         random_indices = np.random.choice(probe_data_coords.shape[0], size=pad_size)\n",
    "#         random_coords = probe_data_coords[random_indices]\n",
    "#         random_values = probe_data_values[random_indices]\n",
    "        \n",
    "#         # Concatenate original and random padded data\n",
    "#         filtered_probe_coords = np.concatenate([probe_data_coords, random_coords], axis=0)\n",
    "#         filtered_probe_values = np.concatenate([probe_data_values, random_values], axis=0)\n",
    "#     else:\n",
    "#         # Truncate if probe data is larger than target_shape_probe\n",
    "#         filtered_probe_coords = probe_data_coords[:target_shape_probe]\n",
    "#         filtered_probe_values = probe_data_values[:target_shape_probe]\n",
    "\n",
    "#     # Combine boundary and probe data back together\n",
    "#     filtered_coords = np.vstack([filtered_boundary_coords, filtered_probe_coords])\n",
    "#     filtered_values = np.vstack([filtered_boundary_values, filtered_probe_values])\n",
    "\n",
    "#     return filtered_coords, filtered_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad to shape of max_id\n",
    "filtered_coords_values = [\n",
    "    pad_to_shape_branch(coords, values, target_shape_boundary=340, target_shape_probe=188) \n",
    "    for coords, values in zip(branch_coords_filtered_list, branch_values_filtered_list)\n",
    "]\n",
    "\n",
    "# Split into separate lists if needed\n",
    "filtered_coords_padded = np.array([item[0] for item in filtered_coords_values])\n",
    "filtered_values_padded = np.array([item[1] for item in filtered_coords_values])\n",
    "\n",
    "m_min = min(arr.shape[0] for arr in output_sensor_coords_filtered_list)\n",
    "\n",
    "# Stack the arrays, trimming each to m_min rows\n",
    "filtered_output_coords_padded = np.stack([arr[-m_min:] for arr in output_sensor_coords_filtered_list])\n",
    "filtered_output_values_padded = np.stack([arr[-m_min:] for arr in output_sensor_values_filtered_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_coords_values[0][0].shape, filtered_coords_values[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure()\n",
    "    plt.scatter(filtered_coords_padded[i, :, 1], filtered_coords_padded[i,:, 0], c=filtered_values_padded[i,:,0], cmap='jet', vmin=0, vmax=1)\n",
    "    plt.xlim([0, T_PRED + T_PAST])\n",
    "    plt.ylim([0, Xmax])\n",
    "    plt.title(f\"t_start = {t_starts[i]}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f\"t_start in tt {t_starts[i] in tt}\")\n",
    "    plt.scatter(filtered_output_coords_padded[i, :, 1], filtered_output_coords_padded[i,:, 0], c=filtered_output_values_padded[i,:], cmap='jet', vmin=0, vmax=1)\n",
    "    plt.xlim([0, T_PRED + T_PAST])\n",
    "    plt.ylim([0, Xmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shapes\n",
    "print(f\"filtered_coords_padded.shape = {filtered_coords_padded.shape}, filtered_values_padded.shape = {filtered_values_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to npz\n",
    "rho_sub = rho[:,:,::5]\n",
    "t_sub = tt[:,::5]\n",
    "filtred_simulation_data = {\n",
    "    'branch_coords': filtered_coords_padded.astype(np.float16),\n",
    "    'branch_values': filtered_values_padded.astype(np.float16),\n",
    "    'output_sensor_coords': filtered_output_coords_padded.astype(np.float16),\n",
    "    'output_sensor_values': filtered_output_values_padded.astype(np.float16),\n",
    "    'rho': rho_sub.astype(np.float16),\n",
    "    # 'v': v.astype(np.float32),  \n",
    "    'x': x.astype(np.float16),\n",
    "    't': t_sub.astype(np.float16),\n",
    "    'Nx': Nx, \n",
    "    'Nt': rho_sub.shape[-1],\n",
    "    'Xmax': Xmax,\n",
    "    'Tmax': Tmax,\n",
    "    'P': P,\n",
    "    'N': N,\n",
    "    # 'keys': keys,\n",
    "    'number_of_probes': n_probes,\n",
    "    't_pred': T_PRED,\n",
    "    't_past': T_PAST,\n",
    "    't_starts': t_starts\n",
    "\n",
    "}\n",
    "\n",
    "# Save the data to an npz file\n",
    "new_path = f'../datasets/godunov_combined_tpast{T_PAST}_tpred{T_PRED}_receding.npz'\n",
    "print(f\"Saving the filtered data to {new_path}\")\n",
    "np.savez(new_path, **filtred_simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = np.load(new_path, allow_pickle=True)\n",
    "\n",
    "memory_stats_npz(data_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graduation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
